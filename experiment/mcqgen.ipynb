{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929eaf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI, ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import LLMChain, SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f035869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.pop(\"OPENROUTER_API_KEY\", None)\n",
    "print(os.getenv(\"OPENROUTER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ccf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f892b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=os.getenv(\"Openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302af538",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=key,\n",
    "    tiktoken_model_name='openai/gpt-oss-20b:free',\n",
    "    temperature=0.7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b659ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\user\\OneDrive\\Desktop\\Generative AI\\genai-github\\response.json\", \"r\") as f:\n",
    "    RESPONSE_JSON = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d492d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "You are an expert MCQ generator.\n",
    "\n",
    "Your task is to create exactly {number} multiple-choice questions (MCQs) \n",
    "for {subject} students using the above text.\n",
    "\n",
    "Difficulty / Tone:\n",
    "{tone}\n",
    "\n",
    "Instructions:\n",
    "- Each question must be clear and relevant to the given text.\n",
    "- Do NOT repeat any questions.\n",
    "- Each MCQ must have four options.\n",
    "- Only one option should be correct.\n",
    "- Ensure all questions are conceptually accurate.\n",
    "\n",
    "Return the output strictly in the JSON format shown below.\n",
    "Do NOT add any extra text outside the JSON.\n",
    "\n",
    "### RESPONSE_JSON\n",
    "{RESPONSE_JSON}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8869b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt=PromptTemplate(\n",
    "    input_variables=['text','number','subject','tone','RESPONSE_JSON'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=quiz_generation_prompt,\n",
    "    output_key='quiz',\n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed2be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 = \"\"\"\n",
    "You are an expert educational content reviewer.\n",
    "\n",
    "Below is a quiz for {subject} students.\n",
    "\n",
    "Your task is to:\n",
    "1. Verify the factual correctness of each MCQ.\n",
    "2. Confirm that the provided correct answers are accurate.\n",
    "3. Improve grammar, clarity, and wording where needed.\n",
    "4. Ensure all questions meet proper academic standards.\n",
    "5. Fix or upgrade any MCQ that has errors or ambiguity.\n",
    "6. Do NOT change the total number of questions.\n",
    "7. Follow the response structure exactly as defined in response.json.\n",
    "\n",
    "### QUIZ DATA\n",
    "{quiz}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(\n",
    "    input_variables=['subject','quiz'],\n",
    "    template=template2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756db497",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=quiz_evaluation_prompt,\n",
    "    output_key='review',\n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain],\n",
    "    input_variables=['text', 'number', 'subject','RESPONSE_JSON', 'tone'],  # combined input vars\n",
    "    output_variables=['quiz', 'review'],                    # plural\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9deb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\user\\OneDrive\\Desktop\\Generative AI\\genai-github\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path,'r') as file:\n",
    "    Text=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text,\n",
    "number=5,\n",
    "subject='AI',\n",
    "tone='simple',\n",
    "RESPONSE_JSON=RESPONSE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"text\": Text,\n",
    "    \"number\": number,\n",
    "    \"subject\": subject,\n",
    "    \"tone\": tone,\n",
    "    \"RESPONSE_JSON\":json.dumps(RESPONSE_JSON)\n",
    "}\n",
    "with get_openai_callback() as cb:\n",
    "    response = generate_evaluate_chain(inputs)  # Direct call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719094ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e567d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db3a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value['mcq']\n",
    "    options=\" | \".join(\n",
    "        [\n",
    "            f\"{option}:{option_value}\"\n",
    "            for option,option_value in value[\"options\"].items()\n",
    "        ]\n",
    "    )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\":mcq,\"Choice\":options,\"Correct\":correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9663821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"genaiquiz1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13107534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
